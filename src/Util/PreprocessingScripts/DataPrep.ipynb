{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(edgeitems=3)\n",
    "np.core.arrayprint._line_width = 999\n",
    "\n",
    "from mlxtend.data import loadlocal_mnist\n",
    "import pathlib\n",
    "from PIL import Image\n",
    "import os\n",
    "import readmat\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: set accordingly\n",
    "data_path_str = ''\n",
    "data_path = pathlib.Path(data_path_str)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "#included here for convenience, can cause errors if imported\n",
    "import pickle\n",
    "\n",
    "class DigitImage:\n",
    "    def __init__(self, image, label):\n",
    "        self.image = image\n",
    "        self.label = label\n",
    "\n",
    "class DigitDataset:\n",
    "    def __init__(self, train_set, test_set):\n",
    "        self.train_set = train_set\n",
    "        self.test_set = test_set\n",
    "\n",
    "\n",
    "def persist_dataset_to_pickle(dataset: DigitDataset, path):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(dataset, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_dataset_from_pickle(path) -> DigitDataset:\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def extract_mnist_imgs(mnist_set):\n",
    "    return [np.reshape(x,(28,28)) for x in list(mnist_set)]\n",
    "\n",
    "def extract_usps_imgs(usps_set):\n",
    "    return [np.reshape(x,(16,16)) for x in list((usps_set*255).astype(np.uint8))]\n",
    "\n",
    "def process_mnistm():\n",
    "    mnistm_path = pathlib.Path(data_path/'mnistm')\n",
    "    train_list = []\n",
    "    test_list = []\n",
    "    for set in os.listdir(mnistm_path):\n",
    "        for label in os.listdir(mnistm_path/set):\n",
    "            for image in os.listdir(mnistm_path/set/label):\n",
    "                img = np.asarray(Image.open(mnistm_path/set/label/image))\n",
    "                if set == 'train':\n",
    "                    train_list.append(DigitImage(img, int(label)))\n",
    "                elif set == 'test':\n",
    "                    test_list.append(DigitImage(img, int(label)))\n",
    "                else:\n",
    "                    raise Exception(f'Set not defined: {set}')\n",
    "    return DigitDataset(train_list, test_list)\n",
    "\n",
    "def process_mnist():\n",
    "    mnist_path = pathlib.Path(data_path/'mnist')\n",
    "    X_train, y_train = loadlocal_mnist(\n",
    "                images_path=mnist_path/'train-images.idx3-ubyte',\n",
    "                labels_path=mnist_path/'train-labels.idx1-ubyte')\n",
    "    X_test, y_test = loadlocal_mnist(\n",
    "                images_path=mnist_path/'t10k-images.idx3-ubyte',\n",
    "                labels_path=mnist_path/'t10k-labels.idx1-ubyte')\n",
    "    X_train_imgs = extract_mnist_imgs(X_train)\n",
    "    x_test_imgs = extract_mnist_imgs(X_test)\n",
    "\n",
    "    train_list = [DigitImage(image , label) for (image, label) in zip(X_train_imgs, y_train)]\n",
    "    test_list = [DigitImage(image, label) for (image, label) in zip(x_test_imgs, y_test)]\n",
    "    return DigitDataset(train_list,test_list)\n",
    "\n",
    "\n",
    "\n",
    "def process_synnum():\n",
    "    synnum_path = pathlib.Path(data_path/'synnum')\n",
    "    synnum_train = readmat.loadmat(synnum_path/'synth_train_32x32.mat')\n",
    "    synnum_test = readmat.loadmat(synnum_path/'synth_test_32x32.mat')\n",
    "    assert synnum_train['y'].shape[-1] == synnum_train['X'].shape[-1] #make sure data and label dimension adds up\n",
    "\n",
    "    train_list = []\n",
    "    test_list = []\n",
    "\n",
    "    train_imgs = np.moveaxis(synnum_train['X'],3,0)\n",
    "    test_imgs = np.moveaxis(synnum_test['X'],3,0)\n",
    "\n",
    "    assert train_imgs.shape[0] == synnum_train['y'].shape[0]\n",
    "    assert test_imgs.shape[0] == synnum_test['y'].shape[0]\n",
    "\n",
    "    for idx in range(train_imgs.shape[0]):\n",
    "        train_list.append(DigitImage(train_imgs[idx], synnum_train['y'][idx]))\n",
    "    for idx in range(test_imgs.shape[0]):\n",
    "        test_list.append(DigitImage(test_imgs[idx], synnum_test['y'][idx]))\n",
    "\n",
    "    return DigitDataset(train_list, test_list)\n",
    "\n",
    "\n",
    "def process_emnist():\n",
    "    emnist_path = pathlib.Path(data_path/'emnist')\n",
    "    emnist = readmat.loadmat(emnist_path/'emnist-digits.mat')\n",
    "\n",
    "    train_list = []\n",
    "    test_list = []\n",
    "\n",
    "    train_imgs = [np.asarray(x).reshape(28,28) for x in emnist['dataset']['train']['images']]\n",
    "    test_imgs = [np.asarray(x).reshape(28,28) for x in emnist['dataset']['test']['images']]\n",
    "\n",
    "    assert len(train_imgs) == len(emnist['dataset']['train']['labels'])\n",
    "    assert len(test_imgs) == len(emnist['dataset']['test']['labels'])\n",
    "\n",
    "    for img, label in zip(train_imgs,emnist['dataset']['train']['labels']):\n",
    "        train_list.append(DigitImage(img, label))\n",
    "    for img, label in zip(test_imgs,emnist['dataset']['test']['labels']):\n",
    "        test_list.append(DigitImage(img, label))\n",
    "\n",
    "    return DigitDataset(train_list, test_list)\n",
    "\n",
    "def process_svhn():\n",
    "    svhn_path = pathlib.Path(data_path/'SVHN')\n",
    "    svhn_train = readmat.loadmat(svhn_path/'train_32x32.mat')\n",
    "    svhn_test = readmat.loadmat(svhn_path/'test_32x32.mat')\n",
    "\n",
    "    train_imgs = np.moveaxis(svhn_train['X'],3,0)\n",
    "    test_imgs = np.moveaxis(svhn_test['X'],3,0)\n",
    "\n",
    "    for idx in range(train_imgs.shape[0]):\n",
    "        if svhn_train['y'][idx] == 10:\n",
    "            svhn_train['y'][idx] = 0\n",
    "\n",
    "    for idx in range(test_imgs.shape[0]):\n",
    "        if svhn_test['y'][idx] == 10:\n",
    "            svhn_test['y'][idx] = 0\n",
    "\n",
    "    train_list = []\n",
    "    test_list = []\n",
    "\n",
    "    assert train_imgs.shape[0] == svhn_train['y'].shape[0]\n",
    "    assert test_imgs.shape[0] == svhn_test['y'].shape[0]\n",
    "\n",
    "    for idx in range(train_imgs.shape[0]):\n",
    "        #labels consider 0 to be 10\n",
    "        train_list.append(DigitImage(train_imgs[idx], svhn_train['y'][idx]))\n",
    "    for idx in range(test_imgs.shape[0]):\n",
    "        #labels consider 0 to be 10\n",
    "        test_list.append(DigitImage(test_imgs[idx], svhn_test['y'][idx]))\n",
    "\n",
    "    return  DigitDataset(train_list, test_list)\n",
    "\n",
    "def process_usps():\n",
    "    usps_path = pathlib.Path(data_path/'usps')\n",
    "    usps_file = usps_path/'usps.h5'\n",
    "\n",
    "    with h5py.File(usps_file, 'r') as hf:\n",
    "            train = hf.get('train')\n",
    "            X_tr = train.get('data')[:]\n",
    "            y_tr = train.get('target')[:]\n",
    "            test = hf.get('test')\n",
    "            X_te = test.get('data')[:]\n",
    "            y_te = test.get('target')[:]\n",
    "\n",
    "    train_list = []\n",
    "    test_list = []\n",
    "\n",
    "    train_imgs = extract_usps_imgs(X_tr)\n",
    "    test_imgs = extract_usps_imgs(X_te)\n",
    "\n",
    "    for img, label in zip(train_imgs,y_tr):\n",
    "        train_list.append(DigitImage(img, label))\n",
    "    for img, label in zip(test_imgs,y_te):\n",
    "        test_list.append(DigitImage(img, label))\n",
    "\n",
    "    return DigitDataset(train_list, test_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% data preprocessing utilities (not needed after initial data extraction)\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "mnist = process_mnist()\n",
    "print('Done')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% load mnist\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "mnist_m = process_mnistm()\n",
    "print('Done')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% load mnist-m\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "synnum = process_synnum()\n",
    "print('Done')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "emnist = process_emnist()\n",
    "print('Done')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "svhn = process_svhn()\n",
    "print('Done')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "usps = process_usps()\n",
    "print('Done')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "save_location_path = pathlib.Path('../../../data')\n",
    "persist_dataset_to_pickle(mnist, save_location_path/'mnist.pkl')\n",
    "persist_dataset_to_pickle(mnist_m, save_location_path/'mnist_m.pkl')\n",
    "persist_dataset_to_pickle(synnum, save_location_path/'synnum.pkl')\n",
    "persist_dataset_to_pickle(emnist, save_location_path/'emnist.pkl')\n",
    "persist_dataset_to_pickle(svhn, save_location_path/'svhn.pkl')\n",
    "persist_dataset_to_pickle(usps, save_location_path/'usps.pkl')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% persist to files as pickle\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}